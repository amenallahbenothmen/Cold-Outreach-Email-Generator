{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "github_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "groq_api_key = os.getenv(\"GROG_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    groq_api_key=groq_api_key, \n",
    "    model_name=\"llama-3.1-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1 (extracting the job offer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Ai Jobs, Employment in Chicago, IL | Indeed.com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Skip to main content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HomeCompany reviewsFind salariesSign inSign inEmployers / Post Job1 new updateStart of main content\n",
      "\n",
      "\n",
      "Keyword : all jobs&nbsp;Edit location input box labelSearchDate postedLast 24 hoursLast 3 daysLast 7 daysLast 14 daysRemoteHybrid workRemoteWithin 25 milesExact location onlyWithin 5 milesWithin 10 milesWithin 15 milesWithin 25 milesWithin 35 milesWithin 50 milesWithin 100 milesPay$90,000+$115,000+$135,000+$160,000+$185,000+Job typeFull-timePart-timeContractTemporaryNewEncouraged to applyfilterLocationChicago, ILItasca, ILEvanston, ILOak Brook, ILRosemont, ILRiver Forest, ILNiles, ILOakbrook Terrace, ILWood Dale, ILBensenville, ILDes Plaines, ILSkokie, ILMaywood, ILIllinoisElk Grove Village, ILCompanyAccentureNorthwestern MedicinePwCVelvetech, LLCDeloitteCapgeminiCapb InfotekNorthwestern UniversityGoogleThe University of ChicagoCodalNorthern Trust Corp.NTT DATACONTRASTMongoDBPosted byEmployerStaffing agencyExperience levelMid LevelSenior LevelEntry LevelNo Experience RequiredEducationHigh school degreeAssociate degreeBachelor's degreeMaster's degreeDoctoral degreeUpload your resume - Let employers find you&nbsp;ai jobs in Chicago, ILSort by: relevance - date800+ jobsData AnalystAIQRemote in Chicago, IL\n",
      "At its inception, Alpine IQ developed a groundbreaking tool to manage customer data compliance across multi-state/ provincial regulatory environments.\n",
      "Â·More...View all AIQ jobs in Chicago, IL - Chicago jobsSalary Search: Data Analyst salaries in Chicago, ILSee popular questions & answers about AIQApplication AnalystNorthwestern MedicineChicago, IL 60611\n",
      "The Application Analyst, reflects the mission, vision, and values of NM, adheres to the organizationâ€™s Code of Ethics and Corporate Compliance Program, andâ€¦\n",
      "Â·More...View all Northwestern Medicine jobs in Chicago, IL - Chicago jobsSalary Search: Application Analyst salaries in Chicago, ILSee popular questions & answers about Northwestern MedicineView similar jobs with this employerApplication Analyst AssociateNorthwestern MedicineChicago, IL 60611\n",
      "The Application Analyst Associate, reflects the mission, vision, and values of NM, adheres to the organizationâ€™s Code of Ethics and Corporate Compliance Programâ€¦\n",
      "Â·More...View all Northwestern Medicine jobs in Chicago, IL - Chicago jobs - Application Analyst jobs in Chicago, ILSalary Search: Application Analyst Associate salaries in Chicago, ILSee popular questions & answers about Northwestern MedicineView similar jobs with this employerContent Optimization SpecialistThe University of Chicago MedicineRemote in Chicago, IL 60637\n",
      "The Content Optimization Specialist is responsible for ensuring the website's content is optimized for search engines, conversions, and user engagement.\n",
      "Â·More...View all The University of Chicago Medicine jobs in Chicago, IL - Chicago jobs - Content Specialist jobs in Chicago, ILSalary Search: Content Optimization Specialist salaries in Chicago, ILSee popular questions & answers about The University of Chicago MedicineReporter - Generative AI in the Newsroom (GAIN)Northwestern UniversityEvanston, IL\n",
      "The reporter will work on a cross-disciplinary, grant-funded project with the Computational Journalism Lab and the Knight Lab teams to help share learnings fromâ€¦\n",
      "Â·More...View all Northwestern University jobs in Evanston, IL - Evanston jobs - News Reporter jobs in Evanston, ILSalary Search: Reporter - Generative AI in the Newsroom (GAIN) salariesSee popular questions & answers about Northwestern UniversityResearch TechnicianThe University of ChicagoChicago, IL 60637Â (Woodlawn area)\n",
      "BSD MED - Rheumatology - Clark Research Staff.\n",
      "During this time, the faculty including Attalah Kappas, M.D.\n",
      "We are seeking to hire a Research Technician in theâ€¦\n",
      "Â·More...View all The University of Chicago jobs in Chicago, IL - Chicago jobsSalary Search: Research Technician salaries in Chicago, ILSee popular questions & answers about The University of ChicagoView similar jobs with this employerDelivery Executive, Contact Center AI, Google CloudGoogleChicago, ILÂ (West Town area)\n",
      "Bachelor's degree or equivalent practical experience.\n",
      "7 years of experience in program management, client services or management consulting.\n",
      "Â·More...View all Google jobs in Chicago, IL - Chicago jobs - Delivery Executive jobs in Chicago, ILSalary Search: Delivery Executive, Contact Center AI, Google Cloud salaries in Chicago, ILSee popular questions & answers about GoogleBi-lingual Call Center Senior Representative (English/Spanish)NTT DATARemote in Chicago, IL 60290\n",
      "Respond to and service customer calls via an inbound ACD system or emails via an email routing client.\n",
      "Educate and inform customers on account related billingâ€¦\n",
      "Â·More...View all NTT DATA jobs in Chicago, IL - Chicago jobs - Call Center Representative jobs in Chicago, ILSalary Search: Bi-lingual Call Center Senior Representative (English/Spanish) salaries in Chicago, ILSee popular questions & answers about NTT DATAView similar jobs with this employerUser Support Specialist (73L)Northwestern UniversityEvanston, IL\n",
      "As a User Support Specialist, you will provide Mac / Windows desktop support to address client-computing needs while assisting in implementing and supporting aâ€¦\n",
      "Â·More...View all Northwestern University jobs in Evanston, IL - Evanston jobs - Support Specialist jobs in Evanston, ILSalary Search: User Support Specialist (73L) salaries in Evanston, ILSee popular questions & answers about Northwestern UniversityConsulting Analyst | OnsitePhotonChicago, IL 60603Â (The Loop area)\n",
      "Is an entry-level or junior role focused on supporting digital transformation projects and initiatives.\n",
      "The role requires a strong foundation in digital tools,â€¦\n",
      "Â·More...View all Photon jobs in Chicago, IL - Chicago jobs - Consultant Configuration Analyst jobs in Chicago, ILSalary Search: Consulting Analyst | Onsite salaries in Chicago, ILSee popular questions & answers about PhotonProject Coordinator (Part Time)DePaul UniversityChicago, IL 60604Â (The Loop area)\n",
      "Coordinates and leads the planning phase for the development of an innovative AI-powered platform designed to assist migrants by integrating real-timeâ€¦\n",
      "Â·More...View all DePaul University jobs in Chicago, IL - Chicago jobs - Project Coordinator jobs in Chicago, ILSalary Search: Project Coordinator (Part Time) salaries in Chicago, ILSee popular questions & answers about DePaul UniversityAI/ML Cloud Consultant, Professional Services, Google CloudGoogleChicago, ILÂ (West Town area)\n",
      "Bachelor's degree in Computer Science, Information Systems, related technical field, or equivalent practical experience.\n",
      "Â·More...View all Google jobs in Chicago, IL - Chicago jobs - Cloud Consultant jobs in Chicago, ILSalary Search: AI/ML Cloud Consultant, Professional Services, Google Cloud salaries in Chicago, ILSee popular questions & answers about GoogleAI Manager (Hybrid)ACE HardwareOak Brook, ILTypically responds within 3 days\n",
      "Ace Hardware Corporation seeks experienced and driven technologists with a strong blend of business acumen, strong interpersonal skills, and technical expertiseâ€¦\n",
      "Â·More...View all ACE Hardware jobs in Oak Brook, IL - Oak Brook jobs - Manager jobs in Oak Brook, ILSalary Search: AI Manager (Hybrid) salaries in Oak Brook, ILSee popular questions & answers about ACE HardwareQuality Assurance AnalystPredictive Sales AIChicago, IL\n",
      "Part of that team is a gatekeeper called a QA analyst, who makes sure that everything throughout the process is in line with industry standards.\n",
      "Â·More...View all Predictive Sales AI jobs in Chicago, IL - Chicago jobsSalary Search: Quality Assurance Analyst salaries in Chicago, ILSee popular questions & answers about Predictive Sales AIManual TesterQualitestHybrid work in Chicago, IL\n",
      "Basic understanding of Quality Assurance or Quality Engineering practices and objectives.\n",
      "A sense of accountability for individual and team objectives, with aâ€¦\n",
      "Â·More...View all Qualitest jobs in Chicago, IL - Chicago jobs - Tester jobs in Chicago, ILSalary Search: Manual Tester salaries in Chicago, ILSee popular questions & answers about Qualitest12345People also searched:dataai internremoteartificial intelligencetensorflowai trainerdata sciencemachine learning engineerpytorchdata scientistResume Resources: Resume Samples - Resume Templates - Resume Writing ServiceCareer Resources: Career ExplorerEmployer Resources: How to Write a Job Description - How to Hire EmployeesReturn to Search ResultJob Post DetailsSenior Data Scientist(AI) - job postQualitest3.43.4 out of 5 starsChicago, IL$135,000 - $150,000 a yearYou must create an Indeed account before continuing to the company website to applyApply nowsave-iconProfile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Data analysis skills?YesNo&nbsp;Job detailsHereâ€™s how the job details align with your profile.Pay$135,000 - $150,000 a year&nbsp;BenefitsPulled from the full job description401(k) matchingGym membershipHealth insuranceHealth savings accountReferral programWellness program&nbsp;Full job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 30 Oct 2024\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Company: Qualitest Group\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "City: Santa Clara\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Country/Region: US\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Qualitest is looking for a talented and detail-oriented Data Scientist to join our assessment team. In this role, you will be responsible for gathering, cleaning, and analyzing data, as well as integrating AI insights into our findings. You'll work closely with team members and stakeholders to present actionable insights and support the maintenance of our AI models.\n",
      "     \n",
      "\n",
      "\n",
      "      Key Requirements:\n",
      "     \n",
      "\n",
      "\n",
      "       Proven experience as a Data Scientist or similar role.\n",
      "      \n",
      "\n",
      "       Experience with exploratory data analysis and pretraining models.\n",
      "      \n",
      "\n",
      "       Familiarity with AI tools and techniques, and the ability to train others in their use.\n",
      "      \n",
      "\n",
      "       Prior experience Gen AI testing 5 TOSCA (AI capabilities).\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Key Responsibilities:\n",
      "     \n",
      "\n",
      "\n",
      "       Collect relevant data from various sources to support our analytical needs\n",
      "      \n",
      "\n",
      "       Ensure data accuracy and consistency through rigorous cleaning and preprocessing techniques.\n",
      "      \n",
      "\n",
      "       Conduct EDA to identify patterns, trends, and insights within the data.\n",
      "      \n",
      "\n",
      "       Utilize pretraining models to derive valuable insights from the data.\n",
      "      \n",
      "\n",
      "       Work closely with assessment team members to integrate AI insights into overall findings.\n",
      "      \n",
      "\n",
      "       Present findings to stakeholders, highlighting actionable steps and recommendations.\n",
      "      \n",
      "\n",
      "       AI Use Cases and Proof of Concept: Clarify AI use cases, conduct proof of concept demonstrations, and train the AI engine.\n",
      "      \n",
      "\n",
      "       Train quality personnel in the use of AI tools and support KPI reporting and effectiveness measures.\n",
      "      \n",
      "\n",
      "       Perform periodic maintenance of AI models to ensure they are up-to-date and reflect current data.\n",
      "      \n",
      "\n",
      "       Conduct recurring data quality checks and preprocessing to support ongoing data maintenance.\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Why QualiTest?\n",
      "     \n",
      "\n",
      "\n",
      "       Be a part of a company who strives to support for diversity and inclusion in the workplace â€“ we are one, we are many at Qualitest. Celebrate culture, share knowledge with engineers from around the globe, and inspire each other through our differences.\n",
      "      \n",
      "\n",
      "       Local and global opportunities â€“ we offer you internal rotation and international mobility opportunities to grow your career.\n",
      "      \n",
      "\n",
      "       Clear view of your career and progression with the company â€“ Qualitest is growing massively and giving you the opportunity to grow with us.\n",
      "      \n",
      "\n",
      "       Work hard and play harder with our flexible and casual culture. Take a break from work and join an employee event, or enjoy the amenities and games provided from one of our Employees Centers.\n",
      "      \n",
      "\n",
      "       Save your earnings and prepare for your future by enrolling in our 401k plan where Qualitest will match your contributions accelerating your savings plan.\n",
      "      \n",
      "\n",
      "       Take care of health with enrollment into one of our competitive healthcare benefits. Qualitest will match towards your HSA if you choose to participate.\n",
      "      \n",
      "\n",
      "       Never stop experimenting and learning with Qualitest Tech academy: 3000+ training courses, mentorship programs, technical tribes, sponsored certifications, leadership programs and much more\n",
      "      \n",
      "\n",
      "       Stay active and get rewarded with our Corporate Wellness Program. We pay your Gym membership and giving you opportunities to Earn additional vacation times for attendance the gym!\n",
      "      \n",
      "\n",
      "       Competitive Salary of $135k- $150k.\n",
      "      \n",
      "\n",
      "       Earn bonuses via our Client Referral and Employee Referral Programâ€™s. Refer and earn â€“ tap your network for net-worth.\n",
      "      \n",
      "\n",
      "       Planning a vacation? Looking for car insurance? Get access to Qualitest Employee Perks for discounts on anything from travel to electronics. With so many offerings the savings are endless!\n",
      "      \n",
      "\n",
      "\n",
      "      Intrigued to find more about us?\n",
      "     \n",
      "\n",
      "\n",
      "       Visit our website: Qualitest Group\n",
      "      \n",
      "\n",
      "\n",
      "      If you like what you have read, send us your resume and letâ€™s start talking!\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "&nbsp;Report jobReturn to Search Result\n",
      "\n",
      "\n",
      "\n",
      "Hiring LabCareer adviceBrowse JobsBrowse CompaniesResume helpSalariesIndeed EventsWork at IndeedCountriesAboutHelp CenterESG at IndeedÂ© 2024 IndeedYour Privacy Choices Accessibility at Indeed Privacy Center and Ad Choices TermsLet Employers Find YouUpload Your Resume\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.indeed.com/jobs?q=ai&l=Chicago%2C+IL&from=searchOnDesktopSerp&vjk=d53bad1ef075b73c\")\n",
    "page_data = loader.load().pop().page_content\n",
    "print(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "  \"title\": \"Senior Data Scientist (AI)\",\n",
      "  \"requirements\": [\n",
      "    \"Proven experience as a Data Scientist or similar role\",\n",
      "    \"Experience with exploratory data analysis and pretraining models\",\n",
      "    \"Familiarity with AI tools and techniques, and the ability to train others in their use\",\n",
      "    \"Prior experience Gen AI testing 5 TOSCA (AI capabilities)\"\n",
      "  ],\n",
      "  \"responsibilities\": \"Collect and analyze data, integrate AI insights, and present findings to stakeholders\",\n",
      "  \"experience_years\": \">0\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### SCRAPED TEXT FROM WEBSITE:\n",
    "    {page_data}\n",
    "    ### INSTRUCTION:\n",
    "    The scraped text is from a career page of a website and describes a single job posting.\n",
    "    Extract and return the details in JSON format, including the following keys:\n",
    "    \n",
    "    - `title`: The main position title for the job.\n",
    "    - `requirements`: A list of all specific requirements mentioned for the job.\n",
    "    - `responsibilities`: A concise summary of the main responsibilities for this role.\n",
    "    - `experience_years`: The required experience in years as an integer.\n",
    "      - If specific years are provided, use that value.\n",
    "      - If experience is implied (e.g., \"senior\" or \"junior\"), set `experience_years` to `>0`.\n",
    "      - If no indication of experience is given, set it to 0.\n",
    "\n",
    "    Only return the valid JSON.\n",
    "    ### VALID JSON (NO PREAMBLE):    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Assuming `page_data` contains the job posting text.\n",
    "chain_extract = prompt | llm \n",
    "res = chain_extract.invoke(input={'page_data': page_data})\n",
    "print(res.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Senior Data Scientist (AI)',\n",
       " 'requirements': ['Proven experience as a Data Scientist or similar role',\n",
       "  'Experience with exploratory data analysis and pretraining models',\n",
       "  'Familiarity with AI tools and techniques, and the ability to train others in their use',\n",
       "  'Prior experience Gen AI testing 5 TOSCA (AI capabilities)'],\n",
       " 'responsibilities': 'Collect and analyze data, integrate AI insights, and present findings to stakeholders',\n",
       " 'experience_years': '>0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "job_offer = json_parser.parse(res.content)\n",
    "job_offer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2 extracting the skills of the user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read me file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_readme_link=\"https://github.com/amenallahbenothmen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_github_readme_raw_link(username):\n",
    "    return f\"https://github.com/{username}/{username}/raw/main/README.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"amenallahbenothmen\"\n",
    "link = get_github_readme_raw_link(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ðŸ’« About Me:\n",
      "Hi there! ðŸ‘‹I'm Amenallah, a final-year engineering student at SUP'COM (Higher School of Communication of Tunis), specializing in data science. Here's a snapshot of my expertise:ðŸ“Š Data Visualization â€“ Crafting insightful visualizations for data-driven decision-making.ðŸ› ï¸ Model Development â€“ Building and fine-tuning models to tackle complex problems.ðŸ¤– Machine Learning & Deep Learning â€“ Applying advanced algorithms and neural networks to unlock AI potential.ðŸŒ Exploring Large Language Models (LLMs) â€“ Currently enhancing my AI skills with the latest in NLP and generative models.Feel free to browse my repositories to see my work in action!\n",
      "\n",
      "\n",
      "## ðŸŒ Socials:\n",
      "[![LinkedIn](https://img.shields.io/badge/LinkedIn-%230077B5.svg?logo=linkedin&logoColor=white)](https://linkedin.com/in/www.linkedin.com/in/amen-allah-ben-othmen-662b78274) \n",
      "\n",
      "# ðŸ’» Tech Stack:\n",
      "![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white) ![Anaconda](https://img.shields.io/badge/Anaconda-%2344A833.svg?style=for-the-badge&logo=anaconda&logoColor=white) ![Flutter](https://img.shields.io/badge/Flutter-%2302569B.svg?style=for-the-badge&logo=Flutter&logoColor=white) ![AmazonDynamoDB](https://img.shields.io/badge/Amazon%20DynamoDB-4053D6?style=for-the-badge&logo=Amazon%20DynamoDB&logoColor=white) ![Firebase](https://img.shields.io/badge/firebase-a08021?style=for-the-badge&logo=firebase&logoColor=ffcd34) ![MySQL](https://img.shields.io/badge/mysql-4479A1.svg?style=for-the-badge&logo=mysql&logoColor=white) ![Figma](https://img.shields.io/badge/figma-%23F24E1E.svg?style=for-the-badge&logo=figma&logoColor=white) ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black) ![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white) ![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white) ![Scipy](https://img.shields.io/badge/SciPy-%230C55A5.svg?style=for-the-badge&logo=scipy&logoColor=%white) ![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white) ![Plotly](https://img.shields.io/badge/Plotly-%233F4F75.svg?style=for-the-badge&logo=plotly&logoColor=white) ![GitHub Actions](https://img.shields.io/badge/github%20actions-%232671E5.svg?style=for-the-badge&logo=githubactions&logoColor=white) ![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white) ![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white)\n",
      "# ðŸ“Š GitHub Stats:\n",
      "![](https://github-readme-streak-stats.herokuapp.com/?user=amenallahbenothmen&theme=dark&hide_border=true)\n",
      "![](https://github-readme-stats.vercel.app/api/top-langs/?username=amenallahbenothmen&theme=dark&hide_border=true&include_all_commits=false&count_private=false&layout=compact)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader2 = WebBaseLoader(link)\n",
    "page_data_2= loader2.load().pop().page_content\n",
    "print(page_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"role\": [\"Data Science Student\", \"Data Scientist\"],\n",
      "    \"experience_duration\": 0,\n",
      "    \"experience\": \"Data Visualization, Model Development, Machine Learning & Deep Learning, Exploring Large Language Models (LLMs)\",\n",
      "    \"skills\": [\"Python\", \"NumPy\", \"Anaconda\", \"Flutter\", \"AmazonDynamoDB\", \"Firebase\", \"MySQL\", \"Figma\", \"Matplotlib\", \"Pandas\", \"scikit-learn\", \"Scipy\", \"TensorFlow\", \"Plotly\", \"GitHub Actions\", \"GitHub\", \"Git\"],\n",
      "    \"description\": \"Final-year engineering student at SUP'COM (Higher School of Communication of Tunis), specializing in data science.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt_2 = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### SCRAPED TEXT FROM GITHUB README:\n",
    "    {page_data_2}\n",
    "    \n",
    "    ### INSTRUCTION:\n",
    "    The scraped text above is from a GitHub README file that provides details about an individual's professional background. \n",
    "    Your task is to extract and format the following information as valid JSON:\n",
    "    \n",
    "    - `role`: A list of roles or titles of the individual, with the main or primary role listed first. If no specific role is mentioned, use the area the individual is specializing in as the primary role.\n",
    "    - `experience_duration`: The number of years of experience as an integer. If the individual is a student, set `experience_duration` to `0`.\n",
    "    - `experience`: A brief summary of relevant experience, including areas of expertise, specific domains, or specializations (e.g., data science, machine learning, cloud computing).\n",
    "    - `skills`: A list of key technical and non-technical skills highlighted in the README, such as programming languages, frameworks, tools, and soft skills.\n",
    "    - `description`: A concise summary that introduces the individual's background, education, or current focus.\n",
    "    \n",
    "    Please follow these rules:\n",
    "    - Only include information that is explicitly mentioned in the README text.\n",
    "    - For `experience_duration`, provide an integer (e.g., `2` for two years of experience, or `0` if the individual is a student).\n",
    "    - If no specific role is found, infer the primary role based on the individual's area of specialization.\n",
    "    - If a specific field is not available, return an empty string (\"\") for text fields or an empty list ([]) for the `skills` field.\n",
    "    - Do not add any explanatory text outside of the JSON format.\n",
    "    \n",
    "    ### VALID JSON (NO PREAMBLE) \n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "chain_extract_2= prompt_2 | llm \n",
    "res_2 = chain_extract_2.invoke(input={'page_data_2':page_data_2})\n",
    "print(res_2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': ['Data Science Student', 'Data Scientist'],\n",
       " 'experience_duration': 0,\n",
       " 'experience': 'Data Visualization, Model Development, Machine Learning & Deep Learning, Exploring Large Language Models (LLMs)',\n",
       " 'skills': ['Python',\n",
       "  'NumPy',\n",
       "  'Anaconda',\n",
       "  'Flutter',\n",
       "  'AmazonDynamoDB',\n",
       "  'Firebase',\n",
       "  'MySQL',\n",
       "  'Figma',\n",
       "  'Matplotlib',\n",
       "  'Pandas',\n",
       "  'scikit-learn',\n",
       "  'Scipy',\n",
       "  'TensorFlow',\n",
       "  'Plotly',\n",
       "  'GitHub Actions',\n",
       "  'GitHub',\n",
       "  'Git'],\n",
       " 'description': \"Final-year engineering student at SUP'COM (Higher School of Communication of Tunis), specializing in data science.\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "json_parser = JsonOutputParser()\n",
    "read_me = json_parser.parse(res_2.content)\n",
    "read_me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## github api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Project Name\": \"BTC_PRICE_PREDICTION_MODEL\",\n",
      "        \"URL\": \"https://github.com/amenallahbenothmen/BTC_PRICE_PREDICTION_MODEL\",\n",
      "        \"Primary Language\": \"Jupyter Notebook\",\n",
      "        \"Project Type\": \"Machine Learning and Data Science\",\n",
      "        \"Main Technologies\": [\n",
      "            \"pandas\",\n",
      "            \"numpy\",\n",
      "            \"yfinance\",\n",
      "            \"tensorflow\",\n",
      "            \"keras-tuner\",\n",
      "            \"joblib\",\n",
      "            \"Flask\",\n",
      "            \"Flask-Cors\",\n",
      "            \"and streamlit\"\n",
      "        ],\n",
      "        \"Primary Goal\": \"Predicting Bitcoin prices using machine learning and data science techniques.\"\n",
      "    },\n",
      "    {\n",
      "        \"Project Name\": \"Cold-Outreach-Email-Generator\",\n",
      "        \"URL\": \"https://github.com/amenallahbenothmen/Cold-Outreach-Email-Generator\",\n",
      "        \"Primary Language\": \"Jupyter Notebook\",\n",
      "        \"Project Type\": \"Natural Language Processing (NLP) and Machine Learning\",\n",
      "        \"Main Technologies\": [\n",
      "            \"python-dotenv\",\n",
      "            \"transformers\",\n",
      "            \"langchain\",\n",
      "            \"bs4\",\n",
      "            \"requests\",\n",
      "            \"chromadb\",\n",
      "            \"aiohttp\"\n",
      "        ],\n",
      "        \"Primary Goal\": \"Automated generation of personalized recommendation letters using NLP and machine learning.\"\n",
      "    },\n",
      "    {\n",
      "        \"Project Name\": \"Emotion_detection\",\n",
      "        \"URL\": \"https://github.com/amenallahbenothmen/Emotion_detection\",\n",
      "        \"Primary Language\": \"Jupyter Notebook\",\n",
      "        \"Project Type\": \"Machine Learning\",\n",
      "        \"Main Technologies\": [\n",
      "            \"Python\",\n",
      "            \"Jupyter Notebook\",\n",
      "            \"Natural Language Processing (NLP) libraries\"\n",
      "        ],\n",
      "        \"Primary Goal\": \"Detecting and analyzing human emotions through text or speech.\"\n",
      "    },\n",
      "    {\n",
      "        \"Project Name\": \"kidney-disease-classification-project-deep-learning-mlflow-project\",\n",
      "        \"URL\": \"https://github.com/amenallahbenothmen/kidney-disease-classification-project-deep-learning-mlflow-project\",\n",
      "        \"Primary Language\": \"Jupyter Notebook\",\n",
      "        \"Project Type\": \"Machine Learning\",\n",
      "        \"Main Technologies\": [\n",
      "            \"TensorFlow\",\n",
      "            \"MLflow\",\n",
      "            \"Pandas\",\n",
      "            \"NumPy\",\n",
      "            \"Matplotlib\",\n",
      "            \"Seaborn\",\n",
      "            \"DVC\",\n",
      "            \"Flask\",\n",
      "            \"Flask-Cors\",\n",
      "            \"Joblib\",\n",
      "            \"tqdm\",\n",
      "            \"ensure\",\n",
      "            \"gdown\",\n",
      "            \"PyYAML\"\n",
      "        ],\n",
      "        \"Primary Goal\": \"Developing a machine learning model for classifying kidney disease with a focus on data management and reproducibility.\"\n",
      "    },\n",
      "    {\n",
      "        \"Project Name\": \"mlflowtest\",\n",
      "        \"URL\": \"https://github.com/amenallahbenothmen/mlflowtest\",\n",
      "        \"Primary Language\": \"Python\",\n",
      "        \"Project Type\": \"Machine Learning\",\n",
      "        \"Main Technologies\": [\n",
      "            \"MLflow\",\n",
      "            \"Python\"\n",
      "        ],\n",
      "        \"Primary Goal\": \"Streamline the machine learning development process, making it easier to collaborate, reproduce results, and deploy models to production environments.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Summarization function for requirements and README using LLM\n",
    "def llm_summarize(content):\n",
    "    \"\"\"Summarize content using the LLM, if content is too long.\"\"\"\n",
    "    prompt_template = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### CONTENT TO SUMMARIZE:\n",
    "        {content}\n",
    "\n",
    "        ### INSTRUCTION:\n",
    "        Provide a concise summary of the content above, focusing on the main technologies, functionality, and purpose if relevant.\n",
    "\n",
    "        ### SUMMARY:\n",
    "        \"\"\"\n",
    "    )\n",
    "    chain = prompt_template | llm\n",
    "    result = chain.invoke(input={'content': content})\n",
    "    return result.content.strip()\n",
    "\n",
    "# Function to get content from requirements.txt and README.md in each project\n",
    "def get_project_content(username, repo_name, token):\n",
    "    headers = {\"Authorization\": f\"token {token}\"}\n",
    "    contents_url = f\"https://api.github.com/repos/{username}/{repo_name}/contents\"\n",
    "    \n",
    "    # Check for requirements.txt\n",
    "    requirements_url = f\"{contents_url}/requirements.txt\"\n",
    "    requirements_response = requests.get(requirements_url, headers=headers)\n",
    "    requirements_content = requests.get(requirements_response.json()[\"download_url\"]).text if requirements_response.status_code == 200 else None\n",
    "    \n",
    "    # Check for README.md\n",
    "    readme_url = f\"{contents_url}/README.md\"\n",
    "    readme_response = requests.get(readme_url, headers=headers)\n",
    "    readme_content = requests.get(readme_response.json()[\"download_url\"]).text if readme_response.status_code == 200 else None\n",
    "    \n",
    "    return requirements_content, readme_content\n",
    "\n",
    "# Main function to fetch and format user projects as JSON\n",
    "def get_user_projects(username, token):\n",
    "    headers = {\"Authorization\": f\"token {token}\"}\n",
    "    projects = []\n",
    "    \n",
    "    # GitHub API URL to fetch user's repositories\n",
    "    url = f\"https://api.github.com/users/{username}/repos\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        repos = response.json()\n",
    "        \n",
    "        # Skip the first repository, assumed to be the profile README\n",
    "        for repo in repos[1:]:  # Start from the second item\n",
    "            repo_name = repo['name']\n",
    "            repo_url = repo['html_url']\n",
    "            language = repo['language']\n",
    "            \n",
    "            # Get requirements and README content\n",
    "            requirements_content, readme_content = get_project_content(username, repo_name, token)\n",
    "            \n",
    "            # Generate a concise description based on project type, technologies, and goal\n",
    "            project_type, technologies, primary_goal = generate_llm_project_summary(repo_name, language, requirements_content, readme_content)\n",
    "            \n",
    "            # Append project data as a dictionary\n",
    "            project_data = {\n",
    "                \"Project Name\": repo_name,\n",
    "                \"URL\": repo_url,\n",
    "                \"Primary Language\": language,\n",
    "                \"Project Type\": project_type,\n",
    "                \"Main Technologies\": technologies.split(\", \"),  # Splitting by comma for a list format\n",
    "                \"Primary Goal\": primary_goal\n",
    "            }\n",
    "            projects.append(project_data)\n",
    "    else:\n",
    "        print(f\"Failed to fetch repositories: {response.status_code}\")\n",
    "    \n",
    "    # Return the projects list in JSON format\n",
    "    return json.dumps(projects, indent=4)\n",
    "\n",
    "# Function to summarize and extract project type, technologies, and primary goal\n",
    "def generate_llm_project_summary(repo_name, language, requirements_content, readme_content):\n",
    "    \"\"\"Generates project type, main technologies, and primary goal using the custom LLM.\"\"\"\n",
    "    \n",
    "    # Summarize requirements and README content using the custom LLM\n",
    "    summarized_requirements = llm_summarize(requirements_content) if requirements_content else \"\"\n",
    "    summarized_readme = llm_summarize(readme_content) if readme_content else \"\"\n",
    "\n",
    "    # Create input data for the LLM based on the summaries\n",
    "    input_data = (\n",
    "        f\"Project Name: {repo_name}\\n\"\n",
    "        f\"Primary Language: {language}\\n\"\n",
    "        f\"Requirements Summary: {summarized_requirements}\\n\"\n",
    "        f\"README Summary:\\n{summarized_readme}\"\n",
    "    )\n",
    "\n",
    "    # Define the LLM prompt template to create a structured project summary\n",
    "    prompt_template = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### PROJECT INFORMATION:\n",
    "        {input_data}\n",
    "\n",
    "        ### INSTRUCTION:\n",
    "        Based on the project name, language, requirements, and README summary above, provide:\n",
    "        - Project Type (e.g., Machine Learning, Data Visualization, Web Application)\n",
    "        - Main Technologies used in the project\n",
    "        - The primary goal or purpose of the project\n",
    "\n",
    "        ### OUTPUT (AS THREE SEPARATE LINES WITHOUT LABELS):\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Invoke the LLM with the summarized input\n",
    "    llm_chain = prompt_template | llm\n",
    "    result = llm_chain.invoke(input={'input_data': input_data})\n",
    "\n",
    "    # Split the output into project type, technologies, and goal\n",
    "    output_lines = result.content.strip().splitlines()\n",
    "    project_type = output_lines[0] if len(output_lines) > 0 else \"\"\n",
    "    technologies = output_lines[1] if len(output_lines) > 1 else \"\"\n",
    "    primary_goal = output_lines[2] if len(output_lines) > 2 else \"\"\n",
    "\n",
    "    return project_type, technologies, primary_goal\n",
    "\n",
    "# Example usage\n",
    "username = \"amenallahbenothmen\"\n",
    "token = github_token\n",
    "projects_output = get_user_projects(username, token)\n",
    "print(projects_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Project Name': 'BTC_PRICE_PREDICTION_MODEL',\n",
       "  'URL': 'https://github.com/amenallahbenothmen/BTC_PRICE_PREDICTION_MODEL',\n",
       "  'Primary Language': 'Jupyter Notebook',\n",
       "  'Project Type': 'Machine Learning and Data Science',\n",
       "  'Main Technologies': ['pandas',\n",
       "   'numpy',\n",
       "   'yfinance',\n",
       "   'tensorflow',\n",
       "   'keras-tuner',\n",
       "   'joblib',\n",
       "   'Flask',\n",
       "   'Flask-Cors',\n",
       "   'and streamlit'],\n",
       "  'Primary Goal': 'Predicting Bitcoin prices using machine learning and data science techniques.'},\n",
       " {'Project Name': 'Cold-Outreach-Email-Generator',\n",
       "  'URL': 'https://github.com/amenallahbenothmen/Cold-Outreach-Email-Generator',\n",
       "  'Primary Language': 'Jupyter Notebook',\n",
       "  'Project Type': 'Natural Language Processing (NLP) and Machine Learning',\n",
       "  'Main Technologies': ['python-dotenv',\n",
       "   'transformers',\n",
       "   'langchain',\n",
       "   'bs4',\n",
       "   'requests',\n",
       "   'chromadb',\n",
       "   'aiohttp'],\n",
       "  'Primary Goal': 'Automated generation of personalized recommendation letters using NLP and machine learning.'},\n",
       " {'Project Name': 'Emotion_detection',\n",
       "  'URL': 'https://github.com/amenallahbenothmen/Emotion_detection',\n",
       "  'Primary Language': 'Jupyter Notebook',\n",
       "  'Project Type': 'Machine Learning',\n",
       "  'Main Technologies': ['Python',\n",
       "   'Jupyter Notebook',\n",
       "   'Natural Language Processing (NLP) libraries'],\n",
       "  'Primary Goal': 'Detecting and analyzing human emotions through text or speech.'},\n",
       " {'Project Name': 'kidney-disease-classification-project-deep-learning-mlflow-project',\n",
       "  'URL': 'https://github.com/amenallahbenothmen/kidney-disease-classification-project-deep-learning-mlflow-project',\n",
       "  'Primary Language': 'Jupyter Notebook',\n",
       "  'Project Type': 'Machine Learning',\n",
       "  'Main Technologies': ['TensorFlow',\n",
       "   'MLflow',\n",
       "   'Pandas',\n",
       "   'NumPy',\n",
       "   'Matplotlib',\n",
       "   'Seaborn',\n",
       "   'DVC',\n",
       "   'Flask',\n",
       "   'Flask-Cors',\n",
       "   'Joblib',\n",
       "   'tqdm',\n",
       "   'ensure',\n",
       "   'gdown',\n",
       "   'PyYAML'],\n",
       "  'Primary Goal': 'Developing a machine learning model for classifying kidney disease with a focus on data management and reproducibility.'},\n",
       " {'Project Name': 'mlflowtest',\n",
       "  'URL': 'https://github.com/amenallahbenothmen/mlflowtest',\n",
       "  'Primary Language': 'Python',\n",
       "  'Project Type': 'Machine Learning',\n",
       "  'Main Technologies': ['MLflow', 'Python'],\n",
       "  'Primary Goal': 'Streamline the machine learning development process, making it easier to collaborate, reproduce results, and deploy models to production environments.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects = json_parser.parse(projects_output)\n",
    "projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client=chromadb.Client()\n",
    "collection = client.create_collection(name='user_data_collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_readme_in_chromadb(readme_data):\n",
    "    # Convert list fields to comma-separated strings\n",
    "    role_str = \", \".join(readme_data['role']) if isinstance(readme_data['role'], list) else readme_data['role']\n",
    "    skills_str = \", \".join(readme_data['skills']) if isinstance(readme_data['skills'], list) else readme_data['skills']\n",
    "    \n",
    "    # Add the document to ChromaDB with formatted metadata\n",
    "    collection.add(\n",
    "        documents=[readme_data['description']],\n",
    "        ids=[\"readme\"],\n",
    "        metadatas={\n",
    "            \"type\": \"README\",\n",
    "            \"role\": role_str,\n",
    "            \"experience_duration\": readme_data['experience_duration'],\n",
    "            \"experience\": readme_data['experience'],\n",
    "            \"skills\": skills_str\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_projects_in_chromadb(projects):\n",
    "    for project in projects:\n",
    "        # Convert main technologies list to a comma-separated string\n",
    "        main_technologies_str = \", \".join(project[\"Main Technologies\"]) if isinstance(project[\"Main Technologies\"], list) else project[\"Main Technologies\"]\n",
    "        \n",
    "        collection.add(\n",
    "            documents=[project[\"Primary Goal\"]],\n",
    "            ids=[project[\"Project Name\"]],\n",
    "            metadatas={\n",
    "                \"type\": \"Project\",\n",
    "                \"project_name\": project[\"Project Name\"],\n",
    "                \"url\": project[\"URL\"],\n",
    "                \"primary_language\": project[\"Primary Language\"],\n",
    "                \"project_type\": project[\"Project Type\"],\n",
    "                \"main_technologies\": main_technologies_str\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_for_application_letter(job_title, job_requirements, job_responsibilities):\n",
    "    query_text = (\n",
    "        f\"Generate a job application letter for the position '{job_title}'. \"\n",
    "        f\"Focus on user projects, skills, and experiences that demonstrate alignment with the following requirements:\\n{job_requirements}\\n\"\n",
    "        f\"and responsibilities:\\n{job_responsibilities}\\n\"\n",
    "        \"Identify relevant information to emphasize the user's qualifications and enthusiasm for the position.\"\n",
    "    )\n",
    "\n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=5  # Retrieve the top 5 relevant documents\n",
    "    )\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_application_letter(job_title, job_requirements, job_responsibilities, query_results):\n",
    "    # Extract the relevant project documents from the query results\n",
    "    relevant_projects = \"\\n\\n\".join(\n",
    "        [f\"- {doc[0]}: {doc[1]}\" for doc in zip(query_results[\"documents\"], query_results[\"metadatas\"])]\n",
    "    )\n",
    "\n",
    "    # Prepare the input data for the application letter\n",
    "    input_data = (\n",
    "        f\"Job Title: {job_title}\\n\"\n",
    "        f\"Requirements: {job_requirements}\\n\"\n",
    "        f\"Responsibilities: {job_responsibilities}\\n\"\n",
    "        f\"Relevant User Projects:\\n{relevant_projects}\"\n",
    "    )\n",
    "\n",
    "    # Define a prompt template to generate the application letter\n",
    "    prompt_template = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB AND USER INFORMATION:\n",
    "        {input_data}\n",
    "\n",
    "        ### INSTRUCTION:\n",
    "        Write a job application letter for the user, emphasizing their relevant skills and experiences in alignment with the job title, requirements, and responsibilities. Mention specific projects by name, placing the project name in parentheses, and briefly explain how each project supports the userâ€™s qualifications and demonstrates their expertise in relation to the jobâ€™s demands.\n",
    "\n",
    "\n",
    "        ### APPLICATION LETTER:\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Generate the letter using the LLM\n",
    "    llm_chain = prompt_template | llm\n",
    "    result = llm_chain.invoke(input={'input_data': input_data})\n",
    "    \n",
    "    return result.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_readme_in_chromadb(read_me)\n",
    "register_projects_in_chromadb(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = job_offer.get(\"title\", \"AI-related role\")\n",
    "job_requirements = \"; \".join(job_offer.get(\"requirements\", []))  # Join list to single string\n",
    "job_responsibilities = job_offer.get(\"responsibilities\", \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Your Name]\n",
      "[Your Address]\n",
      "[City, State ZIP Code]\n",
      "[Date]\n",
      "\n",
      "[Recipientâ€™s Name]\n",
      "[Recipientâ€™s Title]\n",
      "[Company Name]\n",
      "[Company Address]\n",
      "[City, State ZIP Code]\n",
      "\n",
      "Dear [Recipientâ€™s Name],\n",
      "\n",
      "I am excited to apply for the Senior Data Scientist (AI) position at [Company Name]. As a highly motivated and experienced data scientist with a strong background in machine learning and AI, I am confident that I possess the skills and expertise required to excel in this role.\n",
      "\n",
      "With a proven track record of collecting and analyzing data, integrating AI insights, and presenting findings to stakeholders, I am well-equipped to handle the responsibilities of this position. My experience in exploratory data analysis and pretraining models has allowed me to develop a deep understanding of AI tools and techniques, which I am eager to apply in this role.\n",
      "\n",
      "As a data science student and data scientist, I have had the opportunity to work on various projects that demonstrate my expertise in AI and machine learning. For instance, my project on (kidney-disease-classification-project-deep-learning-mlflow-project) showcases my ability to develop and deploy machine learning models using TensorFlow, MLflow, and other relevant technologies. This project involved collecting and analyzing data, integrating AI insights, and presenting findings to stakeholders, which aligns perfectly with the responsibilities of this role.\n",
      "\n",
      "Another project that highlights my expertise in AI is (Cold-Outreach-Email-Generator), which involved using natural language processing (NLP) and machine learning to generate personalized recommendation letters. This project demonstrates my ability to work with large language models (LLMs) and develop innovative solutions using AI.\n",
      "\n",
      "In addition to these projects, I have also worked on (Emotion_detection), which involved detecting and analyzing human emotions through text or speech using NLP and machine learning. This project showcases my ability to work with complex data sets and develop models that can accurately predict human emotions.\n",
      "\n",
      "Furthermore, my experience with MLflow, as demonstrated in my project (mlflowtest), has allowed me to streamline the machine learning development process, making it easier to collaborate, reproduce results, and deploy models to production environments.\n",
      "\n",
      "I am confident that my skills and experience make me an ideal candidate for this role. I am excited about the opportunity to join [Company Name] and contribute to the development of innovative AI solutions. Thank you for considering my application.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "query_results = query_for_application_letter(job_title, job_requirements, job_responsibilities)\n",
    "\n",
    "# Generate the recommendation letter\n",
    "recommendation_letter = generate_application_letter(job_title, job_requirements, job_responsibilities, query_results)\n",
    "print(recommendation_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cold_email",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
